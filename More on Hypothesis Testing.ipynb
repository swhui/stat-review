{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hypothesis Testing\n",
    "\n",
    "In general, a hypothesis tests examines the validity of a null hypothesis versus and alternative hypothesis about some unknown parameter of interest.\n",
    "\n",
    "For example, suppose I have a sample, $X_{1},\\dots, X_{n}$ from some distribution parametrized by an unknown $\\theta$, and we wish to test $$H_{0}: \\theta = 0 \\text{   vs.  } H_{1}: \\theta \\neq 0$$ \n",
    "Then, we establish some test statistic, $T(X_{1}, \\dots, X_{n})$. If the observed test statistic looks unlikely to\n",
    "have come from its null distribution (assuming $\\theta = 0$), we reject in favor of the alternative. Otherwise, we fail to reject.\n",
    "\n",
    "A simple hypothesis is one in which the parameter of interest can only take on one value. Above, the null hypothesis is a simple hypothesis.\n",
    "A composite hypothesis is when a null or alternative hypothesis where the parameter of interest can take on more than one value. Above, the alternative was a composite hypothesis. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Power\n",
    "\n",
    "\n",
    "When we make a decision based on this, there are two undeal situtations:\n",
    "\n",
    "1. Reject $H_{0}$ when $H_{0}$ is true (**Type I Error**)\n",
    "2. Fail to reject $H_{0}$ when the $H_{0}$ is false and should be rejected (**Type II Error**)\n",
    "\n",
    "Fortunately, if with conduct a test with $\\alpha$ significance level, the probability of committing a Type I Error is controlled by $\\alpha$, $\\mathbb{P}(\\text{Type I Error}) \\leq \\alpha$.\n",
    "\n",
    "Thus, when $\\alpha$ is low enough, the probability that we reject the null when we should not is low. Now, we want the probability of committing a Type II Error to be as low as possible. The power of a test is $\\text{Power} = \\mathbb{P}(\\text{reject } H_{0} | H_{1}) = 1 - \\mathbb{P}(\\text{fail to reject } H_{0}|H_{1}) = 1 - \\mathbb{P}(\\text{Type II Error})$; thus, we want our power to be high.\n",
    "\n",
    "\n",
    "### Example\n",
    "\n",
    "Let $X_{1}, \\dots, X_{n} \\sim \\text{Bernoulli}(p)$, with $0 < p < 1$ unknown.\n",
    "\n",
    "Let our hypotheses be:\n",
    "$$H_{0}: p = p_{0}$$ \n",
    "$$H_{1}: p > p_{0}$$\n",
    "and our test statistic under the $H_{0}$ is:\n",
    "$$T(X_{1}, \\dots, X_{n}) = \\frac{\\hat{p} - p_{0}}{\\sqrt{\\frac{p_{0}(1-p_{0})}{n}}}$$\n",
    "and $\\hat{p} = \\frac{1}{n}\\sum_{i=1}^{n}X_{i}$\n",
    "Under $H_{0}$, we can show that $T \\sim N(0,1)$\n",
    "What is the type I and type II error rate?\n",
    "\n",
    "The type I error rate is $\\alpha$.\n",
    "The type II error rate is: $\\mathbb{P}(\\text{Type II error}) = \\mathbb{P}(\\text{fail to reject } H_{0}|H_{1})$. Under $H_{1}$, $p$ can take on any value in the interval $(p_{0}, 1]$\n",
    "\n",
    "Then, we can write the probability of making a type II error as: $\\mathbb{P}(\\text{Type II Error}) = \\mathbb{P}(\\text{fail to reject } H_{0}|p = p_{1})$.  Since there are multiple $p_{1}$, we write the type II error as:\n",
    "\n",
    "$$\\mathbb{P}(\\text{Type II Error}) = \\mathbb{P}(T(X_{1},\\dots,X_{n}) < z_{1-\\alpha}|p=p_{1}) = \\mathbb{P}\\left( \\frac{\\hat{p} - p_{0}}{\\sqrt{\\frac{p_{0}(1-p_{0})}{n}}} < z_{1-\\alpha}|p=p_{1}\\right)$$\n",
    "\n",
    "Under the specific alternative hypothesis $p = p_{1}$, we know that $\\frac{\\hat{p} - p_{1}}{\\sqrt{\\frac{p_{1}(1-p_{1})}{n}}} \\sim N(0, 1)$\n",
    "\n",
    "After some algebra, we can write, $\\frac{\\hat{p} - p_{1}}{\\sqrt{\\frac{p_{1}(1-p_{1})}{n}}} < \\frac{(p_{0} - p_{1})\\sqrt{n}}{\\sqrt{p_{1}(1-p_{1})}} + z_{1-\\alpha} \\sqrt{\\frac{p_{0}(1-p_{0})}{p_{1}(1-p_{1})}}$ and as a result,\n",
    "\n",
    "$$\\mathbb{P}(\\text{Type II Error}) = \\mathbb{P}\\left(  \\frac{\\hat{p} - p_{1}}{\\sqrt{\\frac{p_{1}(1-p_{1})}{n}}} < \\frac{(p_{0} - p_{1})\\sqrt{n}}{\\sqrt{p_{1}(1-p_{1})}} + z_{1-\\alpha} \\sqrt{\\frac{p_{0}(1-p_{0})}{p_{1}(1-p_{1})}} \\bigg| \\thinspace p=p_{1}\\right) = \\Phi \\left( \\frac{(p_{0} - p_{1})\\sqrt{n}}{\\sqrt{p_{1}(1-p_{1})}} + z_{1-\\alpha} \\sqrt{\\frac{p_{0}(1-p_{0})}{p_{1}(1-p_{1})}}  \\right)$$\n",
    "\n",
    "Then, also, power is\n",
    "\n",
    "$$\\text{power }  = 1 - \\Phi \\left( \\frac{(p_{0} - p_{1})\\sqrt{n}}{\\sqrt{p_{1}(1-p_{1})}} + z_{1-\\alpha} \\sqrt{\\frac{p_{0}(1-p_{0})}{p_{1}(1-p_{1})}}  \\right)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Z-test\n",
    "\n",
    "\n",
    "## One-sample z-test\n",
    "\n",
    "\n",
    "Consider a sample $X_{1},..., X_{n}$, and we are given the population standard deviation.\n",
    "We want to test for following hypothesis: $H_{0}: \\mu = \\mu_{0}$ and $H_{1}: \\mu \\neq \\mu_{0}$. Then, we can perform a z-test where $Z = \\frac{ {\\bar X} - \\mu_{0} }{ \\sigma / \\sqrt{n} }$ where, under the null hypothesis, follows a $N(0, 1)$.\n",
    "\n",
    "The p-value is thus ${\\mathbb P}\\left( | Z |  > z_{\\alpha/2} \\bigg| H_{0} \\right)$.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "## Two-sample z-test\n",
    "\n",
    "Consider a sample $X_{11},..., X_{1n}$ from one population and and $X_{21},..., X_{2n}$ from another population.\n",
    "\n",
    "Use this test when we wish to determine if the means of two populations are equal and we know the population standard deviations.\n",
    "\n",
    "Our test statistic is: $Z = \\frac{ ({\\bar X}_{1} - {\\bar X}_{2}) - (\\mu_{1} - \\mu_{2} ) }{ \\sqrt{ \\frac{\\sigma_{1}^{2}}{n_{1}} + \\frac{ \\sigma_{2}^{2} }{n_{2}} } }$\n",
    "\n",
    "Under $H_{0}$, this follows a $N(0, 1)$.\n",
    "\n",
    "The p-value is thus ${\\mathbb P}\\left( | Z |  > z_{\\alpha/2} \\bigg| H_{0} \\right)$.\n",
    "\n",
    "\n",
    "# T-test\n",
    "\n",
    "\n",
    "Note: In order for the test statistic to have a t-distribution, the data needs to be normal, but if the data is not normal, the test statistic has an approximate t-distribution when we have a sample size of at least 30.\n",
    "\n",
    "\n",
    "## One-sample t-test\n",
    "\n",
    "Consider a sample $X_{1},..., X_{n}$, but now we do not know the population standard deviation. Since we introduce another measure of uncertainty, then we estimate $\\sigma$ with $\\hat \\sigma$. Then, we can perform a t-test where $T = \\frac{ {\\bar X} - \\mu_{0} }{ {\\hat \\sigma} / \\sqrt{n} }$ where, under the null hypothesis, follows a $t_{n-2}$.\n",
    "\n",
    "\n",
    "The p-value is thus ${\\mathbb P}\\left( | T |  > t_{\\alpha/2, n-2} \\bigg| H_{0} \\right)$.\n",
    "\n",
    "\n",
    "We can modify the p-value calculation based on the alternative hypothesis.\n",
    "\n",
    "\n",
    "## Two-sample t-test (pooled variance)\n",
    "\n",
    "Consider a sample $X_{11},..., X_{1n}$ from one population and and $X_{21},..., X_{2n}$ from another population.\n",
    "\n",
    "Use this test when we wish to determine if the means of two populations are equal and we do not know the population standard deviations. However, we believe that the standard deviations from the two populations are equal. Then, we used a pooled variance/standard deviation to construct our test statistic.\n",
    "\n",
    "\n",
    "$$T = \\frac{ ({\\bar X}_{1} - {\\bar X}_{2}) - (\\mu_{1} - \\mu_{2} ) }{ \\sqrt{ \\frac{\\sigma_{p}^{2}}{n_{1}} + \\frac{ \\sigma_{p}^{2} }{n_{2}} } }$$\n",
    "\n",
    "where ${\\hat \\sigma}_{p}^{2} = \\frac{ (n_{1} - 1) {\\hat \\sigma}_{1}^{2} + (n_{2}-1) {\\hat \\sigma}_{2}^{2} }{n_{1} + n_{2} - 2}$\n",
    "\n",
    "Under the null, this follows a $t_{n+m-2}$ distribution.\n",
    "\n",
    "## Two-sample t-test (unpooled variance)\n",
    "\n",
    "Consider a sample $X_{11},..., X_{1n}$ from one population and and $X_{21},..., X_{2n}$ from another population.\n",
    "\n",
    "Use this test when we wish to determine if the means of two populations are equal and we do not know the population standard deviations and we do not believe that they are equal. Then, we used an unpooled variance/standard deviation to construct our test statistic.\n",
    "\n",
    "\n",
    "$$T = \\frac{ ({\\bar X}_{1} - {\\bar X}_{2}) - (\\mu_{1} - \\mu_{2} ) }{ \\sqrt{ \\frac{\\sigma_{1}^{2}}{n_{1}} + \\frac{ \\sigma_{2}^{2} }{n_{2}} } }$$\n",
    "\n",
    "The degrees of freedom is more complicated in this case: $df = \\frac{ \\left( \\frac{ {\\hat \\sigma}_{1}^{2} }{n_{1}} + \\frac{ {\\hat \\sigma}_{2}^{2} }{n_{2}}  \\right)^{2} }{   \\frac{ {\\hat \\sigma}_{1}^{4} }{n_{1}^{2} (n_{1} - 1) } + \\frac{ {\\hat \\sigma}_{2}^{4} }{n_{2}^{2} (n_{2} - 1) }   }$\n",
    "\n",
    "\n",
    "# Likelihood Ratio Test\n",
    "\n",
    "In the case of simple hypotheses, we can create a likelihood ratio test between them. In other words, we can consider a simple-vs.-simple hypothesis test for parameter $\\theta$: \n",
    "\n",
    "$H_{0}: \\theta = \\theta_{0}$\n",
    "\n",
    "$H_{1}: \\theta = \\theta_{1}$\n",
    "\n",
    "Then, we can write the likelihood-ratio test statistic as: $\\Lambda = \\frac{ {\\mathcal L} ( \\theta_{1} | x) }{ {\\mathcal L} (\\theta_{0} | x)}$. \n",
    "Here, we can think of this as comparing between two models. The likelihood-ratio test thus gives the following decision rule:  \n",
    "\n",
    "- If $\\Lambda > c$, reject $H_{0}$ \n",
    "- Otherwise, reject $H_{0}$\n",
    "\n",
    "Notice that other sources will may consider the reciprocal of the $\\Lambda$ defined here, in which case our decision rule is also switched.\n",
    "\n",
    "\n",
    " - Neyman-Pearson Lemma: Any other simple test with significance level $\\alpha' \\leq \\alpha$ has a power less than or equal to that of the LRT. In other words, when we have simple hypotheses, the LRT is the most powerful test at that significance level among tests with simple hypotheses.\n",
    "\n",
    "\n",
    "### Example\n",
    "\n",
    "Let $X_{1},\\dots, X_{n} \\overset{i.i.d}{\\sim} \\text{Poisson}(\\lambda)$ with $\\lambda > 0$. Furthermore, let $H_{0}: \\lambda = \\lambda_{0}$ and  $H_{1}: \\lambda = \\lambda_{1}$. Also, assume that $\\lambda_{1} > \\lambda_{0}$.\n",
    "\n",
    "Our likelihood function is, for some $\\lambda$:\n",
    "\n",
    "$\\mathcal{L}(\\lambda) = \\prod_{i=1}^{n} \\frac{e^{-\\lambda}\\lambda^{X_{i}}}{X_{i}!}= \\frac{\\exp \\left\\{ -n\\lambda \\right\\} \\lambda^{\\sum_{i=1}^{n} X_{i}}}{ \\prod_{i=1}^{n} X_{i} ! }$\n",
    "\n",
    "Then, the likelihood-ratio test statistic is\n",
    "\n",
    "$$\\Lambda = \\frac{ {\\mathcal L} ( \\lambda_{1} | x) }{ {\\mathcal L} (\\lambda_{0} | x)} = \\frac{\\exp \\left\\{ -n\\lambda_{1} \\right\\} \\lambda_{1}^{\\sum_{i=1}^{n} X_{i}}}{ \\prod_{i=1}^{n} X_{i} ! } \\frac{ \\prod_{i=1}^{n} X_{i} !  }{ \\exp \\left\\{ -n\\lambda_{0} \\right\\} \\lambda_{0}^{\\sum_{i=1}^{n} X_{i}}  } = \\exp\\left\\{ -n (\\lambda_{1} - \\lambda_{0}) ) \\right\\} \\left( \\frac{\\lambda_{1}}{\\lambda_{0}} \\right)^{\\sum_{i=1}^{n} X_{i} }$$\n",
    "\n",
    "Notice that when $\\Lambda$ is high, then, this means it is much more likely for our data to come from the alternative distribution as opposed to the null distribution. Since $\\lambda_{1} > \\lambda_{0}$, the likelihood ratio is large when $\\sum_{i=1}^{n} X_{i}$ is also large, and we want to reject when $\\Lambda > b$ for some $b$. Then, we can simply consider $\\sum_{i=1}^{n} X_{i} > c$ for some $c$. We know that the sum of Poisson is also Poisson with rate $n\\lambda$. Then, our rejection region is: $\\sum_{i=1}^{n} X_{i} > c$ where for a $\\alpha$ significance level test, $c$ is the $1-\\alpha$ quantile of a $Pois(n\\lambda)$. Under $H_{0}$, it is $Pois(n\\lambda_{0})$, and under $H_{1}$, it is $Pois(n\\lambda_{1})$.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "---\n",
    "\n",
    "Note: There are different variations of the likelihood ratio test, including a generalized ratio test, which considers a set of values that a parameter can take on under the entire possible set of values and under the null hypothesis.\n",
    "\n",
    "Under the generalized likelihood ratio test, we have the following set up: $H_{0}: \\theta \\in \\Theta_{0}$, and our likelihood ratio test statistic is $\\lambda = 2 \\log\\left( \\frac{ \\sup_{\\theta \\in \\Theta} {\\mathcal L}(\\theta)  }{ \\sup_{\\theta \\in \\Theta_{0}} {\\mathcal L}(\\theta) } \\right)=2 \\log\\left( \\frac{{\\mathcal L} }{{ \\mathcal L {\\hat \\theta} }({\\hat \\theta}_{0}) } \\right)$\n",
    "where ${\\hat \\theta}$ is the MLE under the entire space and $\\hat \\theta_{0}$ is the MLE under the restricted space under the null.\n",
    "\n",
    "Furthermore, there is a useful theorem about the limiting distribution of the LRT. \n",
    "\n",
    "Let $\\theta = (\\theta_{1},..., \\theta_{q}, \\theta_{q+1},..., \\theta_{r})$ and say we want to test the null, $\\Theta_{0}: (\\theta_{q+1},..., \\theta_{r} ) = \\theta_{0, q+1},..., \\theta_{0, r}$. Then $\\lambda \\rightarrow \\chi^{2}_{r-q, \\alpha}$ under $H_{0}$.\n",
    "\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## When to use\n",
    "\n",
    "We use z-tests and t-tests when we want to do a one-sample or two-sample tests, and if we know the variance, we opt for the z-test. Generally, however, we do not, so we estimate the variance and use the use a t-test to account for this added uncertainty. Likelihood ratio tests are used when we are comparing simple hypotheses and tests for the goodness-of-fit between two models. Generalized likelihood ratio tests is a general method for testing composite hypotheses.\n",
    "\n",
    "Notice that z-tests and t-tests in particular are limited to comparing at most 2 groups. \n",
    "\n",
    "When we want to test for more than two groups, then we consider ANOVA, MANOVA, etc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ANOVA\n",
    "\n",
    "ANOVA is used to determine whether or not there is a statistically significant difference between means of at least 2 independent groups. ANOVA is used when we are dealing with at least two categories and comparing based on a continuous outcome variable. For instance, perhaps we want to examine if at least 2 different classroom setups lead to different average exam scores. \n",
    "\n",
    "\n",
    "Let's say we have $I$ groups where $I \\geq 2$, each with $J$ observations. We want to answer the following question: Do all of our groups have the same mean? \n",
    "\n",
    "We have the model: $Y_{ij} = \\mu + \\alpha_{i} + \\epsilon_{ij}$\n",
    "\n",
    "The set of hypotheses we want to test are: \n",
    "\n",
    "$H_{0} : \\mu_{1} = \\mu_{2} = ... = \\mu_{I}$ where $I$ are the total number of groups\n",
    "\n",
    "$H_{1}: \\text{at least one group is different}$\n",
    "\n",
    "Equivalently, one can also test: \n",
    "\n",
    "$H_{0} : \\alpha_{i} = 0 \\thinspace \\forall \\thinspace i$ \n",
    "\n",
    "$H_{1}: \\text{at least one } \\alpha_{i} \\text{ is not 0}$\n",
    "\n",
    "\n",
    "Analysis of variance (ANOVA) compares the variability between and within groups to answer this question; in particularly, if the variability between groups is not significantly greater than the variability within groups, then it is likely that the observed differences between group means are not only due to chance. ANOVA is a parametric method, which means that each sample is normally distributed. Furthermore, ANOVA assumes that the observations in each sample are independent and have a common variance.\n",
    "\n",
    "The three main components of ANOVA are:\n",
    "\n",
    " - Sum of squares between: $\\sum_{i=1}^{I} \\sum_{j=1}^{J} ({\\bar Y}_{i \\cdot} - {\\bar Y}_{ \\cdot \\cdot})^{2}$\n",
    " - Sum of squares within: $\\sum_{i=1}^{I} \\sum_{j=1}^{J} ({ Y}_{i j} - {\\bar Y}_{ i \\cdot})^{2}$\n",
    " - Sum of squares total: $\\sum_{i=1}^{I} \\sum_{j=1}^{J} ({ Y}_{i j} - {\\bar Y}_{ \\cdot \\cdot})^{2}$\n",
    "\n",
    "where ${\\bar Y}_{ i \\cdot}$ is the mean for the $i$th group and ${\\bar Y}_{ \\cdot \\cdot}$ is the overall mean.\n",
    "\n",
    "The corresponding statistic, $F$ is calculated: $F = \\frac{ \\frac{SSB}{\\sigma^{2}} / I-1 }{ \\frac{ SSW}{\\sigma^{2}} / (I (J-1)) }$. Under the null hypothesis, it follows an $F_{I-1, I(J-1)}$, where $I-1$ is the df for the SSB and $I(J-1)$ is the df for the SSW.\n",
    "\n",
    "### Example\n",
    "\n",
    "\n",
    "We will use the `iris` dataset and compare petal lengths between the three groups. \n",
    "\n",
    "We are testing for the following set of hypotheses.\n",
    "\n",
    "$H_{0}: \\mu_{setosa} = \\mu_{versicolor} = \\mu_{virginica}$\n",
    "\n",
    "$H_{1}: \\text{at least one group is different}$\n",
    "\n",
    "Below, we calculate our test statistic using the following formula:\n",
    "\n",
    "$F = \\frac{ \\frac{SSB}{\\sigma^{2}} / I-1 }{ \\frac{ SSW}{\\sigma^{2}} / (I (J-1)) }$\n",
    "\n",
    "Here, we have 3 groups, each with 50 observations in each group. As a result, $I=3$ and $J=50$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "species\n",
      "setosa        1.464\n",
      "versicolor    4.260\n",
      "virginica     5.552\n",
      "Name: petal_len, dtype: float64\n",
      "3.7586666666666693\n",
      "1179.0343277002203\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1.1102230246251565e-16"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn import datasets\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "iris = datasets.load_iris()\n",
    "iris_df=pd.DataFrame(iris.data)\n",
    "iris_df['species'] = iris.target\n",
    "iris_df.columns=['sepal_len', 'sepal_wid', 'petal_len', 'petal_wid', 'species']\n",
    "conditions = [\n",
    "    iris_df['species'] == 0,\n",
    "    iris_df['species'] == 1,\n",
    "    iris_df['species'] == 2\n",
    "    ]\n",
    "values = ['setosa',  'versicolor', 'virginica']\n",
    "iris_df['species'] = np.select(conditions, values)\n",
    "group_means = iris_df[['species', 'petal_len']].groupby('species').mean()['petal_len']\n",
    "print(group_means)\n",
    "mean_each_group_obs = np.select(conditions, group_means)\n",
    "grand_mean = np.mean(iris_df['petal_len'])\n",
    "print(grand_mean)\n",
    "n = 50 # 50 observations in each group\n",
    "g = 3 # 3 groups, 'setosa',  'versicolor', 'virginica'\n",
    "num = (n/(g-1))*np.sum((group_means - grand_mean)**2)\n",
    "denom =  (1/(g*(n-1)))* np.sum((iris_df['petal_len'] - mean_each_group_obs )**2 )\n",
    "F = num / denom\n",
    "print(F)\n",
    "df1 = g-1\n",
    "df2 = g*(n-1)\n",
    "p_value = 1- stats.f.cdf(F, df1, df2)\n",
    "p_value"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# $\\chi^{2}$ tests\n",
    "\n",
    "A $\\chi^{2}$ test is a statistical test used to compare observed and expected results. We want to determine if a difference between the observed and expected results is attributed due to chance or if it is not attributed only due to change.\n",
    "\n",
    "\n",
    "## Goodness-of-fit $\\chi^{2}$ test\n",
    "\n",
    "In a $\\chi^{2}$ Goodness-of-fit test, we want to see if the data comes from a specified distribution or not.\n",
    "We may choose to conduct a chi-square goodness-of-fit test when we have a categorical variable with at least two levels. If we have exactly two levels, we may in fact use a z-test. In a goodness of fit test, you calculate the degrees of freedom of number of cell probabilities minus $1$ minus the number of unknown parameters.\n",
    "\n",
    "\n",
    "### Example: Goodness of Fit $\\chi^{2}$ Test Example with 2 Groups\n",
    "\n",
    "A roulette wheel has 38 numbers; 18 are red, 18 are black, and 2 are green. In a fair roulette wheel, the red numbers show up 18 times out of 38. We record the results of 3800 plays and observe 1890 red numbers. Is there evidence to conclude that the roulette is not fair or is this attributed towards change variation? Formulate the null and alternative hypotheses at a significance level of 5\\% and report the p-value.\n",
    "\n",
    "**Answer**: \n",
    "\n",
    "Our goal is to test to see if the wheel we are observing what we would expect to see from a roulette wheel. \n",
    "\n",
    "$H_{0}$: The data comes from a Bernoulli distribution where $P(\\text{observe red}) = \\frac{18}{38}$\n",
    "\n",
    "$H_{1}$: The data does not come from a Bernoulli distribution where $P(\\text{observe red}) \\neq  \\frac{18}{38}$\n",
    "\n",
    "In this case, we have 2 groups, so we will conduct a goodness of fit test with 1 degree of freedom with expected counts of 1800 red numbers and 2000 non-red numbers.\n",
    "\n",
    "\n",
    "I also print out the p-value if we conducted a two-sample z-test; notice that the p-values align."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0034552222675230393\n",
      "0.0034552222675230393\n"
     ]
    }
   ],
   "source": [
    "Obs = np.array([1890, 3800-1890])\n",
    "Exp = np.array([1800, 2000])\n",
    "test_stat = np.sum((Obs-Exp)**2 / Exp)\n",
    "p_value_chi = 1-stats.chi2.cdf(test_stat, 1)\n",
    "p_value_norm = (1- stats.norm.cdf( ((1890-1800)/3800) / np.sqrt((18/38 * 20/38) / 3800)  ))*2\n",
    "print(p_value_chi)\n",
    "print(p_value_norm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## $\\chi^{2}$ test for Independence\n",
    "\n",
    "\n",
    "In a $\\chi^{2}$ independence test, we want to see if two variables are independent or not. You can calculate the degrees of freedom by $(I-1)(J-1)$ where $J$ is the number of levels of variable 1 (column variable) and $I$ is the number of levels of variable 2 (row variable).\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## $\\chi^{2}$ test for Homogeneity\n",
    "\n",
    "In a $\\chi^{2}$ homogeneity test, we want to see if the proportions are differently across the different populations. You can calculate the degrees of freedom by $(I-1)(J-1)$ where $J$ is the number of levels of variable 1 (column variable) and $I$ is the number of levels of variable 2 (row variable)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sources\n",
    "\n",
    "Wasserman, L. (2010). All of statistics: a concise course in statistical inference. New York: Springer. ISBN: 9781441923226 1441923225"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
